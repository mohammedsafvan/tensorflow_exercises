{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fashion_mnist dataset is comes with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting\n",
    "Splitting into training and testing(images, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21 217 123   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   8   1   0  14 200 202 183 237 165  85  24   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 189 221 178 186 199 217 219 219 197 191 133   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   2 165 211 158 197 175 181 178 189 198 231 166   6]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  60 246 206 190 152 189 217 224 221 205 199 212 219  78]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 229 199 171 184 168 162 175 180 207 212 201 211 211   0]\n",
      " [  0   1   0   0   1   0   0   3   0   0   0   0   4 255 183 183 198 175 181 192 166 159 142 143 132 214 101   0]\n",
      " [  0   0   2   4   2   3   0   0   1   0   0  90 253 182 194 186 165 155 182 178 176 188 166 175 180 237 116   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 102 243 193 183 169 166 177 177 184 181 181 178 186 174 145 188 145   0]\n",
      " [  0   0  11   0   0   0   0  38 126 245 221 194 186 175 172 184 192 192 183 177 161 152 159 157 156 190 198   0]\n",
      " [  0 142 217 196 187 224 240 211 219 207 175 141 158 156 158 155 162 162 160 156 162 182 158 169 169 184 213   0]\n",
      " [ 13 222 197 185 189 193 196 187 178 191 187 143 167 173 171 173 177 181 186 193 190 169 159 165 148 178 252   0]\n",
      " [ 34 152 167 173 183 157 156 175 171 166 183 184 180 173 175 177 178 174 169 174 197 184 203 199 188 189 208  10]\n",
      " [131 157  90  88 121 212 211 185 182 174 178 177 186 195 206 220 227 236 233 206 220 202 195 173 148 115 104  18]\n",
      " [  1  92 143 135 102  90 138 175 181 203 206 212 209 195 187 168 141 113  86  77  67  61  58  51  55  60 129 111]\n",
      " [  0   0   0  35 109 109 117  86  87  79  74  69  76  81  90  95  93  92 137 132 134 145 145 148 136 146 158  75]\n",
      " [  2   0   0   0   0   0  37  67 122 110 138 124 123 108  40   1   0   0  77  93  74  70  49  48  39  20   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To show the image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(linewidth=200)\n",
    "INDEX = 89 # Change it\n",
    "plt.imshow(training_images[INDEX]) # The actual image\n",
    "print(training_labels[INDEX]) # The label of the image (1 to 10)\n",
    "print(training_images[INDEX]) # The array representation of the pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing\n",
    "For couple of reason the neural network needs the images in normalized form means 0 to 1 value\n",
    "did you notice tht values in the array represntation, all between 0 to 255\n",
    "so if the value is 215 then normalized is \"215/255.0 = 0.8431372549019608\"\n",
    "we need to normalize all the value in 1 image and several images in  training_images\n",
    "python makes this simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Lets create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,\n",
    "**Sequential**:It simply means sequence of layers\n",
    "**Flatten**:It makes the array flat(1 dimensional set)\n",
    "**Dense**:A layer of neuron\n",
    "    Each layer of neurons need an activation function to tell then what to do\n",
    "**Relu**:Simply \"IF x>0 return x, else return 0\" So the value from this is 0 or greater than 0\n",
    "**Softmax**:Takes a set of values, it picks the biggest one and \n",
    "makes the set true or false (0,1), The biggest one should have the value 1\n",
    "    For example set = [0.5,0.1,0.67,0.12,0.34], The output be like [0,0,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling and fitting\n",
    "our model is ready for compiling\n",
    "we compile the model with optimizer and loss function etc.\n",
    "Then we fit the model means trains the model to catch the patterns of training_images according to labels and given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4972 - accuracy: 0.8263\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3737 - accuracy: 0.8657\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3369 - accuracy: 0.8753\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3130 - accuracy: 0.8859\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2948 - accuracy: 0.8909\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2831 - accuracy: 0.8952\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2684 - accuracy: 0.9008\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2584 - accuracy: 0.9042\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2489 - accuracy: 0.9074\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2396 - accuracy: 0.9109\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2336 - accuracy: 0.9126\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2240 - accuracy: 0.9168\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2178 - accuracy: 0.9186\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2114 - accuracy: 0.9209\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2063 - accuracy: 0.9223\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1985 - accuracy: 0.9254\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1945 - accuracy: 0.9269\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1879 - accuracy: 0.9296\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1845 - accuracy: 0.9300\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b6baa2760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 93% for me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36443883180618286, 0.883400022983551]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's predict all the test_images and check it's accuracy\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.3667400e-12 1.1415671e-12 2.7287106e-09 3.0694054e-13 1.8169773e-10 2.8693119e-06 3.3638186e-09 4.2376900e-03 1.5848857e-11 9.9575943e-01]\n",
      "Predicted label is : 9\n",
      "Actual label is : 9\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(classifications[index])\n",
    "print(f'Predicted label is : {np.argmax(classifications[index])}')\n",
    "print(f'Actual label is : {test_labels[index]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
